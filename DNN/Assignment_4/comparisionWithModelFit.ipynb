{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a89919f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2fd8ab",
   "metadata": {},
   "source": [
    "Load & Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4113eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255\n",
    "y_train, y_test = to_categorical(y_train, num_classes=10), to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f873f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(28, 28))\n",
    "    x = Flatten()(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66ffba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "loss_fn = CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a62b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_fn(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99999993",
   "metadata": {},
   "source": [
    "train model with gradient tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a937f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjoy-kumar/.local/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:593: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2025-06-22 20:39:05.588776: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2470\n",
      "Epoch 2, Loss: 0.1046\n",
      "Epoch 3, Loss: 0.0752\n",
      "Epoch 4, Loss: 0.0582\n",
      "Epoch 5, Loss: 0.0457\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(32)\n",
    "\n",
    "for epoch in range(5):\n",
    "    epoch_loss = tf.keras.metrics.Mean()\n",
    "    for images, labels in train_dataset:\n",
    "        loss = train_step(model, images, labels)\n",
    "        epoch_loss.update_state(loss)\n",
    "    print(f'Epoch {epoch + 1}, Loss: {epoch_loss.result().numpy():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad4deb4",
   "metadata": {},
   "source": [
    "Evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97ee9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GradientTape Final Test Accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    predictions = model(images, training=False)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "\n",
    "print(f'\\nGradientTape Final Test Accuracy: {test_accuracy.result().numpy():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab8aba",
   "metadata": {},
   "source": [
    "Training using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78708a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8569 - loss: 0.4740 - val_accuracy: 0.9587 - val_loss: 0.1333\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1147 - val_accuracy: 0.9684 - val_loss: 0.1053\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0772 - val_accuracy: 0.9716 - val_loss: 0.0853\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0605 - val_accuracy: 0.9759 - val_loss: 0.0790\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0455 - val_accuracy: 0.9766 - val_loss: 0.0754\n"
     ]
    }
   ],
   "source": [
    "model2 = create_model()\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77aa0c",
   "metadata": {},
   "source": [
    "Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e145c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Performance Comparison ---\n",
      "GradientTape Final Test Accuracy: 0.9769\n",
      "model.fit() Final Test Accuracy:    0.9766\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Performance Comparison ---\")\n",
    "print(f\"GradientTape Final Test Accuracy: {test_accuracy.result().numpy():.4f}\")\n",
    "fit_test_accuracy = history.history['val_accuracy'][-1]\n",
    "print(f\"model.fit() Final Test Accuracy:    {fit_test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
