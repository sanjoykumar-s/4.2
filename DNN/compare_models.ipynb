{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0991665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95f3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = \"road.mp4\"\n",
    "MODELS_TO_TEST = [\n",
    "    # n -> nano version\n",
    "    \"yolov8n.pt\",\n",
    "    \"yolo11n.pt\",\n",
    "    \"yolo12n.pt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8826e62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---model: yolov8n.pt ---\n",
      "Processed 255 frames. Output saved to: road_yolov8n_output.mp4\n",
      "\n",
      "---model: yolo11n.pt ---\n",
      "Processed 255 frames. Output saved to: road_yolo11n_output.mp4\n",
      "\n",
      "---model: yolo12n.pt ---\n",
      "Processed 255 frames. Output saved to: road_yolo12n_output.mp4\n",
      "\n",
      "\n",
      "--- FINAL BENCHMARK SUMMARY ---\n",
      "================================================================================\n",
      "Model           | Avg Inference (ms)   | FPS        | Total Detections    \n",
      "--------------------------------------------------------------------------------\n",
      "yolov8n.pt      | 68.09                | 14.69      | 5098                \n",
      "yolo11n.pt      | 70.71                | 14.14      | 4826                \n",
      "yolo12n.pt      | 95.38                | 10.48      | 4932                \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "VIDEO_PATH = \"road.mp4\"\n",
    "MODELS_TO_TEST = [\n",
    "    \"yolov8n.pt\",\n",
    "    \"yolo11n.pt\",\n",
    "    \"yolo12n.pt\"\n",
    "]\n",
    "\n",
    "def objectDetection(video_path, model_name):\n",
    "\n",
    "    print(f\"\\n---model: {model_name} ---\")\n",
    "    \n",
    "    model = YOLO(model_name)\n",
    "\n",
    "    video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "    frame_gen = sv.get_video_frames_generator(source_path=video_path)\n",
    "\n",
    "    # Annotator for the bounding box\n",
    "    box_annotator = sv.BoxAnnotator(\n",
    "        thickness=2\n",
    "    )\n",
    "    # Annotator for the bounding box\n",
    "    label_annotator = sv.LabelAnnotator(\n",
    "        text_thickness=1,\n",
    "        text_scale=0.5\n",
    "    )\n",
    "    \n",
    "    # setup for output video\n",
    "    output_filename = f\"{video_path.split('.')[0]}_{model_name.split('.')[0]}_output.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_filename, fourcc, video_info.fps, video_info.resolution_wh)\n",
    "\n",
    "    total_inference_time_ms = 0\n",
    "    frame_count = 0\n",
    "    total_detections = 0\n",
    "\n",
    "    for frame in frame_gen:\n",
    "        frame_count += 1\n",
    "        start_time = time.time()\n",
    "        result = model(frame, verbose=False)[0] \n",
    "        end_time = time.time()\n",
    "\n",
    "        inference_time_ms = (end_time - start_time) * 1000\n",
    "        total_inference_time_ms += inference_time_ms\n",
    "\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "        total_detections += len(detections)\n",
    "\n",
    "        labels = [\n",
    "            f\"{model.names[int(class_id)]} {confidence:.2f}\"\n",
    "            for confidence, class_id\n",
    "            in zip(detections.confidence, detections.class_id)\n",
    "        ]\n",
    "\n",
    "        annotated_frame = box_annotator.annotate(\n",
    "            scene=frame.copy(),\n",
    "            detections=detections\n",
    "        )\n",
    "\n",
    "        annotated_frame = label_annotator.annotate(\n",
    "            scene=annotated_frame,\n",
    "            detections=detections,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        out.write(annotated_frame)\n",
    "    \n",
    "    out.release()\n",
    "\n",
    "    print(f\"Processed {frame_count} frames. Output saved to: {output_filename}\")\n",
    "\n",
    "    avg_inference_time_ms = total_inference_time_ms / frame_count if frame_count > 0 else 0\n",
    "    fps = 1000 / avg_inference_time_ms if avg_inference_time_ms > 0 else 0\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"avg_inference_time_ms\": avg_inference_time_ms,\n",
    "        \"fps\": fps,\n",
    "        \"total_detections\": total_detections\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    benchmark_results = []\n",
    "    \n",
    "    for model_name in MODELS_TO_TEST:\n",
    "        result = objectDetection(VIDEO_PATH, model_name)\n",
    "        if result:\n",
    "            benchmark_results.append(result)\n",
    "\n",
    "    print(\"\\n\\n--- FINAL BENCHMARK SUMMARY ---\")\n",
    "    print(\"=\" * 80) \n",
    "    print(f\"{'Model':<15} | {'Avg Inference (ms)':<20} | {'FPS':<10} | {'Total Detections':<20}\")\n",
    "    print(\"-\" * 80) \n",
    "    \n",
    "    # Sort results by FPS (highest first) for easy comparison\n",
    "    for result in sorted(benchmark_results, key=lambda x: x['fps'], reverse=True):\n",
    "        print(f\"{result['model']:<15} | {result['avg_inference_time_ms']:<20.2f} | {result['fps']:<10.2f} | {result['total_detections']:<20}\")\n",
    "    print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
